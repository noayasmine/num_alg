{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4006c230-0f0a-442b-b07c-e3ac087afbb2",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06d3e5bf55c941ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Homework set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b4bf1-32e3-4ac4-b7f6-ec2c254dce13",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-736ff6bc3e0d0696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Monday December 2**. **Submit the notebook file with your answers (as .ipynb file) and a pdf printout. The pdf version can be used by the teachers to provide feedback. On canvas there are hints about creating a nice pdf version.**\n",
    "\n",
    "Before you hand in, please make sure the notebook runs, by running \"Restart kernel and run all cells...\" from the Kernel menu.\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1859055d-08e7-4ea9-a150-3e516aca8149",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b13bc5ed16bce8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb9f94-3dc9-4065-9acc-1f0f2159592a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd464f55ba436b1c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "\n",
    "Noa Roebersen, 12247014\n",
    "\n",
    "Paul Jungnickel, 15716554\n",
    "\n",
    "\n",
    "\n",
    "$$\\newcommand{\\bfA}{\\boldsymbol{A}}\n",
    "\\newcommand{\\bfB}{\\boldsymbol{B}}\n",
    "\\newcommand{\\bfJ}{\\boldsymbol{J}}\n",
    "\\newcommand{\\bfr}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bfs}{\\boldsymbol{s}}\n",
    "\\newcommand{\\bfx}{\\boldsymbol{x}}\n",
    "\\newcommand{\\for}{\\text{\\bf for }}\n",
    "\\newcommand{\\end}{\\text{\\bf end }}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6e7f5-fd21-4513-b257-6aaafd1b51e9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5a7855ecca9f6be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to import NumPy, Matplotlib. If anything else is needed you can import this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e35cc-be36-4289-8ccc-3538644c6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=9, floatmode='fixed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef387050-61e8-4b0d-b004-fc829b6322a9",
   "metadata": {},
   "source": [
    "# Exercise 1: Nonlinear least squares\n",
    "\n",
    "This exercise is about the Gauss-Newton method, and the Levenberg-Marquardt method, which are discussed in section 6.6 of Heath. Please read this section before making this homework set. **In this exercise set the Levenberg-Marquardt method is a little different from the one in Heath. The first equation in subsection 6.6.2 is replaced by**\n",
    "$$\n",
    "\\renewcommand{\\bfA}{\\boldsymbol{A}}\n",
    "\\renewcommand{\\bfB}{\\boldsymbol{B}}\n",
    "\\renewcommand{\\bfJ}{\\boldsymbol{J}}\n",
    "\\renewcommand{\\bfr}{\\boldsymbol{r}}\n",
    "\\renewcommand{\\bfs}{\\boldsymbol{s}}\n",
    "\\renewcommand{\\bfx}{\\boldsymbol{x}}\n",
    "\\renewcommand{\\for}{\\text{\\bf for }}\n",
    "\\renewcommand{\\end}{\\text{\\bf end }}\n",
    "\\bigg(\\bfJ^T(\\bfx_k) \\bfJ(\\bfx_k) \n",
    "+ \\mu_k \\operatorname{Diagonal}\\big( \\bfJ^T(\\bfx_k) \\bfJ(\\bfx_k) \\big) \\bigg) \\bfs_k\n",
    "= - \\bfJ^T(\\bfx_k) \\, \\bfr(\\bfx_k)\n",
    "$$\n",
    "Here $\\operatorname{Diagonal}(\\bfB)$ denotes the diagonal part of $\\bfB$. So $\\operatorname{Diagonal}(\\bfB)$ has the same shape as $\\bfB$ and identical entries on the diagonal and it has zero off-diagonal entries.\n",
    "\n",
    "The algorithm for Levenberg-Marquardt, with $\\mu_k$ constant (denoted $\\mu$ here), is then</br>\n",
    "$\\qquad \\bfx_0 = \\text{initial guess}$</br>\n",
    "$\\qquad \\mu = \\text{constant}$</br>\n",
    "$\\qquad \\for k = 0,1,2, \\ldots$</br>\n",
    "$\\qquad \\qquad \\bfA = \\bfJ_f(\\bfx_k)$</br>\n",
    "$\\qquad \\qquad \\text{solve } \\bfs_k \\text{ from } \n",
    "(\\bfA^T \\bfA + \\mu \\operatorname{Diagonal}(\\bfA^T \\bfA)) \\bfs_k = - \\bfA^T \\bfr(\\bfx_k)$</br>\n",
    "$\\qquad \\qquad \\bfx_{k+1} = \\bfx_k + \\bfs_k$</br>\n",
    "$\\qquad \\end$</br>\n",
    "\n",
    "This reduces to the Gauss-Newton method if $\\mu = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51052506-f62f-45c1-a980-faaec89e7260",
   "metadata": {},
   "source": [
    "## (a)\n",
    "Implement the Levenberg-Marquardt method with constant $\\mu$ using a suitable stopping criterion. \n",
    "Make it such that the user can specify the value of the tolerance in the stopping criterion via a parameter `tol` and the maximum number of iterations via a\n",
    "parameter `maxIter`. In the implementation you can use library functions for linear algebra operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c75b12-ae54-4b5f-8cee-8c9f3a1a3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinearLeastSquares(t, y, f, J,  x0, mu, tol=1e-6, max_iter = 100):\n",
    "    \"\"\"\"\n",
    "    Solves the nonlinear least squares problem with the Levenberg-Marquardt method\n",
    "    \n",
    "    Arguments:\n",
    "        - t, y : data to be fitted as time series\n",
    "        - f, J : Model and its jacobian for all t\n",
    "        - x0: starting guess\n",
    "        - mu: sensitivity of Levenberg-Marquardt - smaller mu mean more agressive but less accurate steps\n",
    "        - tol: tolerance of the approximation\n",
    "        - max_iter: maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "        - x: model parameters that give the best fit\n",
    "    \"\"\"\n",
    "\n",
    "    k, xk, sk = 0, x0.copy(), 1e100*np.ones_like(x0),\n",
    "    rk = y - f(xk, t)\n",
    "\n",
    "    print(\"iteration,\\t\\t x, \\t\\t\\t\\t |r|\")\n",
    "\n",
    "    while(np.linalg.norm(sk) > tol and k<max_iter):\n",
    "\n",
    "        print(k+1,'\\t\\t', xk,'\\t\\t',  np.linalg.norm(rk))\n",
    "\n",
    "        A = J(xk, t)\n",
    "\n",
    "        Arr = A.T @ A\n",
    "        Arr = Arr + mu*np.diag(np.diag(Arr))\n",
    "\n",
    "        rk = y - f(xk, t)\n",
    "        JTrk = -A.T @  rk\n",
    "\n",
    "        if not (np.isnan(Arr).any() or np.isnan(JTrk).any()):\n",
    "            sk, _, _, _ = np.linalg.lstsq(Arr, JTrk)        \n",
    "        else:\n",
    "            print(\"Method diverged\")\n",
    "            return xk\n",
    "\n",
    "\n",
    "        xk += sk\n",
    "\n",
    "        k+=1\n",
    "\n",
    "\n",
    "    return xk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe3f2bc-3459-4565-a21c-3418508fd181",
   "metadata": {},
   "source": [
    "## (b) \n",
    "\n",
    "The time course of drug concentration $y$ in the bloodstream is well described by\n",
    "$$ \\tag{1}\n",
    "  y = c_1 t e^{c_2 t} ,\n",
    "$$\n",
    "where $t$ denotes time after the drug was administered. The characteristics of the model\n",
    "are a quick rise as the drug enters the bloodstream, followed by slow exponential decay.\n",
    "The half-life of the drug is the time from the peak concentration to the time it drops to\n",
    "half that level. The measured level of the drug norfluoxetine in a patient's bloodstream at whole hours after it was administered is given in the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9b61c-0ceb-43b0-9391-e8d237281bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in hours\n",
    "hour = np.array( [ 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0 ] )\n",
    "# concentration in ng/ml\n",
    "concentration = np.array( [ 8.0, 12.3, 15.5, 16.8, 17.1, 15.8, 15.2, 14.0 ] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b973cc-1086-436d-80fd-aab3849892ed",
   "metadata": {},
   "source": [
    "Use the Gauss-Newton method to fit this data to the blood concentration model (1).\n",
    "\n",
    "Also use the Levenberg-Marquardt method with $\\mu =0.1$ to address the same problem.\n",
    "\n",
    "Which method produces the least number of iterations? N.B. clearly state the starting point. \n",
    "\n",
    "You are asked to use your own version of Gauss-Newton and Levenberg-Marquardt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb23f18",
   "metadata": {},
   "source": [
    "We select a starting point of $c_1 = 10$ and $c_2 = -0.1$, since $c_1$ has to be negative to get a decay and $c_1$ should roughly correspond to the initial concentration value.\n",
    "\n",
    "The Gauss-Newton (GN) method converges much more quickly with only 6 iterations compared to 29 vor Levenberg-Marquardt (LM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03a550-182d-4603-b72b-be6c62d25940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#Defining the model function and its Jacobian:\n",
    "def f(x,t):\n",
    "    return x[0] * t * np.exp(x[1]*t)\n",
    "\n",
    "def Jf(x, tArr):\n",
    "    return -1.* np.array([[t*np.exp(x[1]*t), x[0]*(t**2)*np.exp(x[1]*t)] for t in tArr])\n",
    "    \n",
    "\n",
    "\n",
    "#starting guess\n",
    "x0 = np.array([10.,-.1])\n",
    "\n",
    "#solve the system with Gauss-Newton:\n",
    "mu = 0.0\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)\n",
    "\n",
    "#plot the fit cuve along with the data\n",
    "plt.plot(hour, concentration, marker='o', linestyle='', label='data')\n",
    "\n",
    "tArr = np.linspace(hour[0], hour[-1], 100)\n",
    "plt.plot(tArr, f(x, tArr), label=r'model $x_0 t e^{x_1 t}$')\n",
    "plt.title(\"Data with fitted model\")\n",
    "plt.legend()\n",
    "plt.xlabel('time [hours]')\n",
    "plt.ylabel('concentration [ng/ml]')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c120d9",
   "metadata": {},
   "source": [
    "Solving the same LLS problem with the Levenberg-Marquardt method where $\\mu=0.1$, we get the same result, but this method requires 29 iterations to converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10933e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nLM converges in 29 iterations:\")\n",
    "mu = 0.1\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1fa65-7d08-4c6d-95a1-f628f1cd3832",
   "metadata": {},
   "source": [
    "# (c)\n",
    "Try to find a starting point such that Gauss-Newton does not converge, while Levenberg-Marquardt does.\n",
    "\n",
    "Just changing $c_2$ from $-0.1$ to $-0.5$ is enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a6ce9-5972-4752-b4f2-0b98784496d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#worse starting guess\n",
    "x0 = np.array([10.,-.5])\n",
    "\n",
    "print(\"Gauss-Newton does not converge:\")\n",
    "mu = 0.0\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nLM does converge in 33 iterations:\")\n",
    "mu = 0.1\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3db79a-df39-42cd-b50e-7e818536d6ce",
   "metadata": {},
   "source": [
    "# (d) \n",
    "So far for simplicity, we considered constant $\\mu$. However\n",
    "Levenberg-Marquardt is often applied adaptively with a varying $\\mu$. \n",
    "A common strategy is to continue to decrease $\\mu$ by a factor of 10 on each iteration step as long as the residual sum of squared errors is decreased by the step, and if the sum increases, to reject the step and increase $\\mu$ by a factor of 10.\n",
    "\n",
    "Implement an adaptive variant of Levenberg-Marquardt using such a strategy for choosing $\\mu$. \n",
    "\n",
    "Compare the performance (iteration number) of the adaptive variant with Gauss-Newton and the previous, non-adaptive variant of Levenberg-Marquardt. Consider a starting point for which Gauss-Newton converged rapidly and a starting point for which Gauss-Newton did not converge, but non-adaptive Levenberg-Marquardt did. Give your answer in a table for clarity, also indicating the starting point and if relevant other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eefc00d-80ba-48a8-b122-65f8f87bf5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinearLeastSquares(t, y, f, J,  x0, mu=0.1, tol=1e-6, max_iter = 100):\n",
    "    \"\"\"\"\n",
    "    Solves the nonlinear least squares problem with the adaptive Levenberg-Marquardt method\n",
    "    \n",
    "    Arguments:\n",
    "        - t, y : data to be fitted as time series\n",
    "        - f, J : Model and its jacobian for all t\n",
    "        - x0: starting guess\n",
    "        - mu: starting sensitivity of Levenberg-Marquardt - smaller mu mean more agressive but less accurate steps\n",
    "                gets automatically adapted during the iterations\n",
    "        - tol: tolerance of the approximation\n",
    "        - max_iter: maximum number of iterations\n",
    "    \n",
    "    Returns:\n",
    "        - x: model parameters that give the best fit\n",
    "    \"\"\"\n",
    "    k, xk, sk, = 0, x0.copy(), 1e100*np.ones_like(x0)\n",
    "    rk = y - f(xk, t)\n",
    "    \n",
    "    print(\"iteration,\\t\\t x, \\t\\t\\t\\t |r|\")\n",
    "    \n",
    "    while(np.linalg.norm(sk) > tol and k<max_iter):\n",
    "\n",
    "        print(k+1,'\\t\\t', xk,'\\t\\t',  np.linalg.norm(rk))\n",
    "\n",
    "        A = J(xk, t)\n",
    "\n",
    "        Arr = A.T @ A\n",
    "        Arr = Arr + mu*np.diag(np.diag(Arr))\n",
    "\n",
    "        JTrk = -A.T @  rk\n",
    "\n",
    "        if not (np.isnan(Arr).any() or np.isnan(JTrk).any()):\n",
    "            sk, _, _, _ = np.linalg.lstsq(Arr, JTrk)        \n",
    "        else:\n",
    "            print(\"Method diverged\")\n",
    "            return xk\n",
    "        \n",
    "        \n",
    "        #only accept the iteration if residual norm decreases and adapt mu\n",
    "        rk_new = y - f(xk + sk, t)\n",
    "\n",
    "        errorDiff = np.linalg.norm(rk_new) - np.linalg.norm(rk)\n",
    "        if errorDiff > 0:\n",
    "            mu *= 10\n",
    "\n",
    "        else:\n",
    "            mu /= 10\n",
    "            xk += sk\n",
    "            rk = rk_new\n",
    "\n",
    "\n",
    "        k+=1\n",
    "\n",
    "\n",
    "\n",
    "    return xk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c77ecf",
   "metadata": {},
   "source": [
    "For testing the method we use the same points [10,-0.1] and [10,-0.5] as in b) and c)\n",
    "\n",
    "Starting point where both methods converged:\n",
    "LM now takes 6 compared to 29 iterations, same as GN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#worse starting guess\n",
    "x0 = np.array([10.,-.1])\n",
    "\n",
    "\n",
    "print(\"\\nLM converges in 6 iterations:\")\n",
    "mu = 0.1\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8e4cf6",
   "metadata": {},
   "source": [
    "Starting point where GN diverged:\n",
    "LM now converges in 8 compared to 33 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cf1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#worse starting guess\n",
    "x0 = np.array([10.,-.5])\n",
    "\n",
    "\n",
    "print(\"\\nLM converges in 8 iterations:\")\n",
    "mu = 0.1\n",
    "x = nonlinearLeastSquares(hour, concentration, f, Jf, x0, mu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introcls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
